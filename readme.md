# Porygon 系統架構設計文檔

## 1. 系統概述

Porygon 是一個基於 AI 代理的服務系統，旨在提供智能查詢和互動功能。系統由多個組件組成，包括 API 服務、MLflow 追蹤服務、Airflow 工作流服務和各種 AI 代理實現。

### 1.1 設計理念

系統設計基於以下核心理念：

- **模組化**: 將系統分解為獨立且可替換的組件
- **可擴展性**: 設計支持未來添加更多類型的代理和功能
- **可維護性**: 清晰的代碼結構和文檔
- **可靠性**: 健全的錯誤處理和日誌記錄

## 2. 系統架構圖

```
+------------------+      +------------------+      +------------------+
|    Client     | ---> |    API Service       | ---> |   MLflow     |
|  (用戶界面/請求)  |      | (處理請求/響應)   |      | (模型管理/部署)  |
+------------------+      +------------------+      +------------------+
                                  |
                                  |
                                  v
                          +------------------+
                          |   AI Agent    |
                          | (處理查詢/推理)  |
                          +------------------+
                                  |
                                  |
                                  v
                          +------------------+
                          |   LLM API    |
                          |   (Grok/XAI)    |
                          +------------------+
```

## 3. 核心組件詳解

### 3.1 API 服務 (porygon/service/api_service)

FastAPI 實現的 RESTful API 服務，負責處理用戶請求、驗證請求內容、與模型交互並返回響應。

主要特點：

- 基於 FastAPI 開發，提供高性能非同步處理
- 實現請求日誌記錄和錯誤處理
- 使用依賴注入管理服務實例
- 提供 OpenAPI 文檔

關鍵元素：

- **Router**: 定義 API 路由和端點
- **Service**: 實現具體業務邏輯
- **Schema**: 定義數據模型和驗證規則
- **Middleware**: 實現認證和日誌等中間件功能

### 3.2 MLflow 追蹤服務 (porygon/service/mlflow-tracking)

管理 AI 模型的生命週期，包括訓練、版本控制、部署和監控。

主要功能：

- 模型註冊與版本管理
- 模型部署和服務化
- 實驗跟踪與比較
- 模型性能監控

### 3.3 Airflow 服務 (porygon/service/airflow)

管理和調度批處理工作流，用於數據處理、模型訓練和評估等任務。

主要功能：

- 任務排程與依賴管理
- 工作流監控與重試機制
- 執行日誌記錄
- 通知與報告

### 3.4 AI 代理 (porygon/agent)

實現各種 AI 代理，如 Wikipedia 代理、聊天代理等。

主要類型：

- **Wikipedia 代理**: 搜索和檢索 Wikipedia 知識
- **聊天代理**: 提供對話和互動功能

技術實現：

- 基於 LangChain 框架
- 使用 Grok-2-1212 語言模型
- 與外部 API 集成

## 4. 數據流

### 4.1 請求處理流程

1. 客戶端發送 HTTP 請求到 API 服務
2. API 服務驗證請求並解析參數
3. 服務層（Service）處理業務邏輯，調用模型進行推理
4. 模型生成結果返回給服務層
5. 服務層格式化結果並通過 API 返回給客戶端

### 4.2 模型加載流程

1. 服務啟動時，初始化 MLflow 客戶端
2. 從環境變數獲取模型 URI
3. 使用 MLflow Python 客戶端加載模型
4. 模型加載後保存在 AI 服務的實例中
5. 後續請求直接使用已加載的模型進行推理

## 5. 技術選型與依賴

### 5.1 核心技術

- **Python**: 主要開發語言
- **FastAPI**: Web 框架
- **MLflow**: 模型管理平台
- **Airflow**: 工作流管理平台
- **Docker**: 容器化技術
- **LangChain**: LLM 工作流框架

### 5.2 主要依賴

- **uvicorn**: ASGI 服務器
- **pydantic**: 數據驗證
- **gunicorn**: 生產級 WSGI 服務器
- **langchain-xai**: AI 模型集成

## 6. 部署架構

### 6.1 開發環境

- 使用 Docker Compose 本地運行所有服務
- MLflow 服務連接到本地數據庫（MySQL/PostgreSQL）
- API 服務連接到本地 MLflow 服務

### 6.2 生產環境

- API 服務部署到 Cloud Run 或 Kubernetes
- MLflow 服務部署到獨立的服務實例
- 使用 Cloud SQL 或其他託管數據庫服務
- 使用 GCS 或其他對象存儲服務存儲模型文件

## 7. 安全性考慮

### 7.1 API 認證

- 使用 API 密鑰進行身份驗證
- 基於角色的訪問控制 (RBAC)
- 支持不同級別的權限（管理員、數據科學家、訪客等）

### 7.2 數據安全

- HTTPS 加密傳輸
- 敏感配置使用環境變數或密鑰管理系統
- 日誌記錄中排除敏感信息

## 8. 擴展性設計

### 8.1 添加新代理

系統設計支持輕鬆添加新的 AI 代理：

1. 在 `porygon/agent` 目錄下創建新代理實現
2. 在 MLflow 中註冊部署新模型
3. 在 `porygon_api/app/agent/v1` 目錄中添加對應的 API 實現
4. 在路由配置中註冊新端點

### 8.2 業務擴展

系統支持以下擴展方向：

- 集成更多語言模型和 AI 服務
- 添加更多特定領域的代理
- 實現高級功能，如多輪對話和上下文管理
- 添加用戶反饋和持續學習機制

## 9. 監控與可觀察性

### 9.1 日誌記錄

- 使用結構化日誌記錄請求、處理過程和錯誤
- 記錄關鍵指標，如
